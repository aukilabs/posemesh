<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Posemesh QR Scanner</title>
    <style>
        body {
            margin: 0;
            padding: 0;
            width: 100vw;
            height: 100vh;
            overflow: hidden;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
        }

        #container {
            position: relative;
            width: 100%;
            height: 100%;
        }

        #video {
            position: absolute;
            width: 100%;
            height: 100%;
            object-fit: cover;
            display: none;
            /* Hidden until stream starts */
        }

        #canvas {
            position: absolute;
            width: 100%;
            height: 100%;
            object-fit: cover;
        }

        .detected {
            background-color: rgba(0, 255, 0, 0.3);
            color: #00ff00;
        }

        .not-detected {
            background-color: rgba(255, 0, 0, 0.3);
            color: #ff0000;
        }

        #startButton {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            padding: 16px 32px;
            font-size: 20px;
            font-weight: bold;
            background-color: #4CAF50;
            color: white;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            transition: all 0.3s ease;
        }

        #startButton:hover {
            background-color: #45a049;
            transform: translate(-50%, -50%) scale(1.05);
        }

        #startButton:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
            transform: translate(-50%, -50%) scale(1);
        }
    </style>
</head>

<body>
    <div id="container">
        <video id="video" playsinline autoplay></video>
        <canvas id="canvas"></canvas>
        <button id="startButton">Start Camera</button>
    </div>

    <script src="Posemesh.js"></script>
    <script>
        let currentResizeMultiplier = 1;
        let currentCorners = [];
        let hasDetectedQR = false;

        let processingFrame = false;

        async function initPosemesh() {
            await Posemesh.initializePosemesh();
        }

        async function requestCameraPermission() {
            try {
                // First just check if we have permission
                const permissionResult = await navigator.permissions.query({ name: 'camera' });
                if (permissionResult.state === 'granted') {
                    return true;
                }

                // If not granted, request it
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        facingMode: 'environment',
                        width: { ideal: 1280 },
                        height: { ideal: 720 }
                    }
                });
                // Stop the stream immediately - we just needed the permission
                stream.getTracks().forEach(track => track.stop());
                return true;
            } catch (err) {
                console.error('Error requesting camera permission:', err);
                return false;
            }
        }

        async function startCamera() {
            console.log("Starting camera...");
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        facingMode: 'environment',
                        width: { ideal: 1280 },
                        height: { ideal: 720 }
                    }
                });
                const video = document.getElementById('video');
                video.srcObject = stream;
                console.log("Start playing video...");
                await video.play();
                console.log("Camera feed started!");

                // Show video, hide start button
                video.style.display = 'block';
                document.getElementById('startButton').style.display = 'none';

                // Start processing frames
                console.log("Starting frame processing...");
                // setInterval(processFrame, 1000);
                setInterval(processFrameLuminance, 16);
                //setTimeout(processFrame, 1000);

                // let stream_settings = stream.getVideoTracks()[0].getSettings();

                // // actual width & height of the camera video
                // let stream_width = stream_settings.width;
                // let stream_height = stream_settings.height;

                // console.log('Webcam stream width: ' + stream_width + 'px');
                // console.log('Webcam stream height: ' + stream_height + 'px');
            } catch (err) {
                console.error('Error starting camera:', err);
                alert('Could not start camera. Please ensure camera permissions are granted.');
            }
        }

        function processFrameLuminance() {
            // console.log(`Processing frame... (timestamp = ${new Date().toISOString()})`);
            if (processingFrame) {
                // console.log("Already processing frame. Skip processing.");
                return;
            }

            processingFrame = true;
            // console.log("Processing frame...");
            const video = document.getElementById('video');
            const canvas = document.getElementById('canvas');
            const ctx = canvas.getContext('2d', { willReadFrequently: true });

            // Match canvas size to video
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            let imageWidth = video.videoWidth;
            let imageHeight = video.videoHeight;
            const originalWidth = imageWidth;
            const originalHeight = imageHeight;

            const encodedImageInBytes = imageWidth * imageHeight * 8;
            const currentMaxBytes = 17760256; // bytes, value taken from error message. Reduce to force image resulution reduction.
            const diff = currentMaxBytes - encodedImageInBytes;
            // console.log(`Encoded size will be ${(encodedImageInBytes / 1000000).toFixed(2)} MB, limit is ${currentMaxBytes / 1000000} MB.`);
            if (diff < 0) {
                const aspectRatio = originalWidth / originalHeight;
                imageWidth = imageWidth / 2;
                imageHeight = imageWidth / aspectRatio;
                // console.log(`Resizing image ${originalWidth}x${originalHeight} -> ${imageWidth}x${imageHeight} (${(imageWidth * imageHeight * 8 / 1000000).toFixed(2)} MB)`);
            }

            canvas.width = imageWidth;
            canvas.height = imageHeight;

            // Store image size reduction factor so it can be used to calculate corner positions in the full resolution image.
            currentResizeMultiplier = originalWidth / imageWidth;

            // Draw camera feed on camera canvas.
            ctx.drawImage(video, 0, 0, imageWidth, imageHeight);
            processImageDataBytes(ctx.getImageData(0, 0, imageWidth, imageHeight), imageWidth, imageHeight, canvas);

            drawCorners(ctx, currentCorners);

            processingFrame = false;
        };

        function getGreyEncodedImage(imageData, width, height) {
            const startTime = performance.now();
            const byteData = imageData.data;
            const greyEncodedImageData = [];
            for (let i = 0; i < 4 * width * height; i += 4) { // 4 for each RGBA component.
                const greyValue = 0.299 * (byteData[i + 2] / 255.0) + 0.587 * (byteData[i + 1] / 255.0) + 0.114 * (byteData[i] / 255.0);
                greyEncodedImageData.push(greyValue * 255.0);
            }

            const endTime = performance.now();
            // console.log(`Encoding image data took ${(endTime - startTime).toFixed(2)}ms`);
            return greyEncodedImageData;
        }

        function processImageDataBytes(imageData, width, height, canvas) {
            const imageBytes = getGreyEncodedImage(imageData, width, height);
            const contents = [];
            const corners = [];

            const startTime = performance.now();
            const detected = Posemesh.QRDetection.detectQRFromLuminance(imageBytes, width, height, contents, corners);
            const endTime = performance.now();

            // console.log(`QR detection took ${(endTime - startTime).toFixed(2)}ms`);
            // console.log(`Detected ${contents.length} QRs with a total of ${corners.length} corners`);

            hasDetectedQR = detected;
            if (detected) {
                currentCorners = corners;
                poseEstimateSingleQR(corners, canvas);
            }
        }

        const focalLength = 932.0900126242127;
        let squareLength = 0.05;

        function poseEstimateSingleQR(corners, canvas) {
            let objectPoints = [], imagePoints = [], cameraMatrix = undefined, outR = undefined, outT = undefined;
            try {

                let o0 = new Posemesh.Vector3();
                objectPoints.push(o0);
                o0.x = -squareLength / 2;
                o0.y = squareLength / 2;

                let o1 = new Posemesh.Vector3();
                objectPoints.push(o1);
                o1.x = squareLength / 2;
                o1.y = squareLength / 2;

                let o2 = new Posemesh.Vector3();
                objectPoints.push(o2);
                o2.x = squareLength / 2;
                o2.y = -squareLength / 2;

                let o3 = new Posemesh.Vector3();
                objectPoints.push(o3);
                o3.x = -squareLength / 2;
                o3.y = -squareLength / 2;

                for (let i = 0; i < 4; i++) {
                    let point = new Posemesh.Vector2();
                    point.x = corners[i].x;
                    point.y = corners[i].y;
                    imagePoints.push(point);
                }

                // Data from https://www.calibdb.net/
                cameraMatrix = new Posemesh.Matrix3x3();
                cameraMatrix.m00 = focalLength;
                cameraMatrix.m02 = 1280 / 2; // 638.6549019259521;
                cameraMatrix.m11 = focalLength;
                cameraMatrix.m12 = 720 / 2; // 342.9911521888232; 
                cameraMatrix.m22 = 1;

                outR = new Posemesh.Matrix3x3();
                outT = new Posemesh.Vector3();

                let estimationSuccess = Posemesh.PoseEstimation.solvePnP(objectPoints, imagePoints, cameraMatrix, outR, outT);
                // console.log('Estimation success =', estimationSuccess);
                // console.log(`outR = [${outR.m00}, ${outR.m01},  ${outR.m02},\n${outR.m10}, ${outR.m11},  ${outR.m12},\n${outR.m20}, ${outR.m21},  ${outR.m22}]`);
                // console.log(`outT = (${outT.x}, ${outT.y}, ${outT.z})`);
                drawCube(canvas, outT, outR);
            } finally {
                if (outT) {
                    outT.delete();
                }
                if (outR) {
                    outR.delete();
                }
                if (cameraMatrix) {
                    cameraMatrix.delete();
                }
                for (let imagePoint of imagePoints) {
                    imagePoint.delete();
                }
                for (let objectPoint of objectPoints) {
                    objectPoint.delete();
                }
            }
        }

        function drawCorners(ctx, corners) {
            // ctx.clearRect(0, 0, canvas.width, canvas.height);

            if (corners.length == 0) return;

            // Circles
            const radius = 5;
            ctx.fillStyle = 'red';
            corners.forEach(corner => {
                ctx.beginPath(); // Start a new path
                ctx.arc(corner.x, corner.y, radius, 0, Math.PI * 2);
                ctx.fill();
            });
        }

        // 3D cube vertices (8 vertices for a cube centered at the origin)
        const cubeVertices = [
            [-1, -1, -1], [1, -1, -1], [1, 1, -1], [-1, 1, -1], // Front face
            [-1, -1, 1], [1, -1, 1], [1, 1, 1], [-1, 1, 1],  // Back face
            [0, 0, 0], [0, 0, 30] // Z direction edge
        ];

        // Function to project 3D coordinates onto 2D canvas
        function project3DTo2D(x, y, z, width, height) {
            const px = (x * focalLength) / z + width / 2;
            const py = (y * focalLength) / z + height / 2;
            return [px, py];
        }

        // Function to multiply a 3D point by a rotation matrix
        function rotatePoint(point, matrix) {
            const [x, y, z] = point;
            const rotatedX = matrix.m00 * x + matrix.m01 * y + matrix.m02 * z;
            const rotatedY = matrix.m10 * x + matrix.m11 * y + matrix.m12 * z;
            const rotatedZ = matrix.m20 * x + matrix.m21 * y + matrix.m22 * z;
            return [rotatedX, rotatedY, rotatedZ];
        }

        function scalePoint(point) {
            let [x, y, z] = point;
            const scale = squareLength / 2;
            x *= scale;
            y *= scale;
            z *= scale / 10;
            return [x, y, z];
        }

        // Function to draw the cube
        function drawCube(canvas, outT, outR) {
            const ctx = canvas.getContext('2d', { willReadFrequently: true });
            ctx.clearRect(0, 0, canvas.width, canvas.height); // Clear the canvas

            // Apply rotation and translation to all cube vertices
            const transformedVertices = cubeVertices.map(vertex => {
                const rotatedVertex = rotatePoint(scalePoint(vertex), outR); // Apply rotation
                const [tx, ty, tz] = [rotatedVertex[0] + outT.x, rotatedVertex[1] + outT.y, rotatedVertex[2] + outT.z]; // Apply translation
                return [tx, ty, tz];
            });

            // Project 3D vertices to 2D
            const projectedVertices = transformedVertices.map(vertex => {
                const [x, y, z] = vertex;
                return project3DTo2D(x, y, z, canvas.width, canvas.height);
            });
            // console.log(projectedVertices);

            // Draw cube edges (connecting the vertices)
            const edges = [
                [0, 1], [1, 2], [2, 3], [3, 0], // Front face
                [4, 5], [5, 6], [6, 7], [7, 4], // Back face
                [0, 4], [1, 5], [2, 6], [3, 7], // Connecting front and back
                [8, 9] // Z-edge
            ];

            edges.forEach(([startIdx, endIdx]) => {
                const [x1, y1] = projectedVertices[startIdx];
                const [x2, y2] = projectedVertices[endIdx];
                ctx.beginPath();
                ctx.moveTo(x1, y1);
                ctx.lineTo(x2, y2);
                if (startIdx < 4) {
                    ctx.strokeStyle = 'red';
                }
                else if (startIdx < 8) {
                    ctx.strokeStyle = 'green';
                } else {
                    ctx.strokeStyle = 'blue';    
                }
                ctx.lineWidth = 3
                ctx.stroke();
            });
        }

        // Initialize
        initPosemesh();

        // Add click handler to start button
        document.getElementById('startButton').onclick = async () => {
            const button = document.getElementById('startButton');
            button.disabled = true;
            button.textContent = 'Requesting Permission...';

            if (await requestCameraPermission()) {
                startCamera();
            } else {
                button.disabled = false;
                button.textContent = 'Start Camera';
                alert('Camera permission denied. Please allow camera access and try again.');
            }
        };
    </script>
</body>

</html>